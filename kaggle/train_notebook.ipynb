{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# DYLUMO - Image to Music Training\n",
        "\n",
        "This notebook trains a FastMLP model to map image features to music features.\n",
        "\n",
        "**Architecture:** CLIP Image Features (512-dim) → FastMLP → Spotify Audio Features (13-dim)\n",
        "\n",
        "## BEFORE RUNNING:\n",
        "\n",
        "1. **Enable GPU**: Click **Settings** (gear icon) → **Accelerator** → Select **\"GPU T4 x2\"**\n",
        "2. Click **\"Run All\"** and wait ~30 minutes\n",
        "\n",
        "**Both datasets download automatically!**\n",
        "\n",
        "---\n",
        "\n",
        "**Datasets:**\n",
        "- Spotify 1M Tracks (from Kaggle)\n",
        "- EMID Images (from HuggingFace)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cell 1: Install packages and setup\n",
        "!pip install open-clip-torch faiss-cpu huggingface_hub pyarrow -q\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from tqdm.auto import tqdm\n",
        "from PIL import Image\n",
        "from pathlib import Path\n",
        "import pickle\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Set seeds for reproducibility\n",
        "np.random.seed(42)\n",
        "torch.manual_seed(42)\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f'Device: {device}')\n",
        "if device.type == 'cuda':\n",
        "    print(f'GPU: {torch.cuda.get_device_name(0)}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cell 2: Download and load Spotify dataset\n",
        "AUDIO_FEATURES = ['danceability', 'energy', 'key', 'loudness', 'mode', 'speechiness', \n",
        "                  'acousticness', 'instrumentalness', 'liveness', 'valence', 'tempo', \n",
        "                  'duration_ms', 'time_signature']\n",
        "\n",
        "# Try multiple possible paths for Spotify data\n",
        "SPOTIFY_PATHS = [\n",
        "    '/kaggle/input/spotify-1million-tracks/spotify_data.csv',  # If added via UI\n",
        "    '/kaggle/working/spotify/spotify_data.csv'  # If downloaded via API\n",
        "]\n",
        "\n",
        "spotify_path = None\n",
        "for path in SPOTIFY_PATHS:\n",
        "    if os.path.exists(path):\n",
        "        spotify_path = path\n",
        "        break\n",
        "\n",
        "# Download if not found\n",
        "if spotify_path is None:\n",
        "    print('Spotify dataset not found. Downloading from Kaggle...')\n",
        "    import subprocess\n",
        "    os.makedirs('/kaggle/working/spotify', exist_ok=True)\n",
        "    \n",
        "    # Download using Kaggle API (available in Kaggle notebooks)\n",
        "    result = subprocess.run(\n",
        "        ['kaggle', 'datasets', 'download', '-d', 'amitanshjoshi/spotify-1million-tracks', \n",
        "         '-p', '/kaggle/working/spotify', '--unzip'],\n",
        "        capture_output=True, text=True\n",
        "    )\n",
        "    \n",
        "    if result.returncode == 0:\n",
        "        spotify_path = '/kaggle/working/spotify/spotify_data.csv'\n",
        "        print('Download complete!')\n",
        "    else:\n",
        "        print(f'Download error: {result.stderr}')\n",
        "        raise FileNotFoundError(\n",
        "            \"Could not download Spotify dataset.\\n\"\n",
        "            \"Please add it manually: Click '+ Add Data' → Search 'spotify-1million-tracks' → Add\"\n",
        "        )\n",
        "\n",
        "print(f'Loading Spotify data from: {spotify_path}')\n",
        "spotify_df = pd.read_csv(spotify_path)\n",
        "print(f'Loaded {len(spotify_df):,} Spotify tracks')\n",
        "\n",
        "# Normalize features\n",
        "scaler = MinMaxScaler()\n",
        "features_norm = scaler.fit_transform(spotify_df[AUDIO_FEATURES])\n",
        "\n",
        "# Map to emotions\n",
        "def map_emotion(v, e):\n",
        "    if v >= 0.5:\n",
        "        return 'excitement' if e >= 0.7 else 'amusement' if e >= 0.5 else 'contentment'\n",
        "    return 'anger' if e >= 0.7 else 'fear' if e >= 0.5 else 'sadness'\n",
        "\n",
        "spotify_df['emotion'] = spotify_df.apply(lambda r: map_emotion(r['valence'], r['energy']), axis=1)\n",
        "for i, c in enumerate(AUDIO_FEATURES):\n",
        "    spotify_df[f'{c}_norm'] = features_norm[:, i]\n",
        "\n",
        "print(spotify_df['emotion'].value_counts())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cell 3: Download EMID dataset from HuggingFace (automatic)\n",
        "from huggingface_hub import list_repo_files, hf_hub_download\n",
        "import pyarrow.parquet as pq\n",
        "\n",
        "os.makedirs('/kaggle/working/emid/images', exist_ok=True)\n",
        "os.makedirs('/kaggle/working/emid/raw', exist_ok=True)\n",
        "\n",
        "files = list_repo_files('ecnu-aigc/EMID', repo_type='dataset')\n",
        "parquet_files = [f for f in files if f.endswith('.parquet')]\n",
        "\n",
        "for pf in tqdm(parquet_files, desc='Downloading EMID'):\n",
        "    hf_hub_download(repo_id='ecnu-aigc/EMID', repo_type='dataset', filename=pf, local_dir='/kaggle/working/emid/raw')\n",
        "\n",
        "hf_hub_download(repo_id='ecnu-aigc/EMID', repo_type='dataset', filename='EMID_data.csv', local_dir='/kaggle/working/emid')\n",
        "print('Download complete!')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cell 4: Extract images from parquet files\n",
        "images_dir = Path('/kaggle/working/emid/images')\n",
        "saved = 0\n",
        "for pq_file in tqdm(list(Path('/kaggle/working/emid/raw/data').glob('*.parquet'))):\n",
        "    df = pq.read_table(pq_file).to_pandas()\n",
        "    for idx, row in df.iterrows():\n",
        "        for col in ['Image1_filename', 'Image2_filename', 'Image3_filename']:\n",
        "            try:\n",
        "                d = row[col]\n",
        "                if d and 'bytes' in d and d['bytes']:\n",
        "                    fn = os.path.basename(d.get('path', f'{col}_{idx}.jpg'))\n",
        "                    p = images_dir / fn\n",
        "                    if not p.exists():\n",
        "                        p.write_bytes(d['bytes'])\n",
        "                        saved += 1\n",
        "            except: pass\n",
        "print(f'Extracted {saved} images')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cell 5: Prepare EMID metadata\n",
        "emid_df = pd.read_csv('/kaggle/working/emid/EMID_data.csv')\n",
        "img_data = []\n",
        "for _, row in emid_df.iterrows():\n",
        "    for i in [1,2,3]:\n",
        "        fn, tag = row[f'Image{i}_filename'], row[f'Image{i}_tag']\n",
        "        if pd.notna(fn): img_data.append({'filename': fn, 'emotion': tag})\n",
        "\n",
        "images_df = pd.DataFrame(img_data).drop_duplicates('filename')\n",
        "images_df['exists'] = images_df['filename'].apply(lambda x: (images_dir/x).exists())\n",
        "images_df = images_df[images_df['exists']].reset_index(drop=True)\n",
        "print(f'{len(images_df)} images ready')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cell 6: Extract CLIP features from images (GPU accelerated)\n",
        "import open_clip\n",
        "\n",
        "print('Loading CLIP model...')\n",
        "clip_model, _, clip_preprocess = open_clip.create_model_and_transforms('ViT-B-32', pretrained='openai')\n",
        "clip_model = clip_model.to(device).eval()\n",
        "print('CLIP model loaded!')\n",
        "\n",
        "all_feats = []\n",
        "for i in tqdm(range(0, len(images_df), 64), desc='CLIP'):\n",
        "    batch = images_df.iloc[i:i+64]\n",
        "    imgs = [clip_preprocess(Image.open(images_dir/r['filename']).convert('RGB')) for _,r in batch.iterrows()]\n",
        "    with torch.no_grad():\n",
        "        t = torch.stack(imgs).to(device)\n",
        "        f = clip_model.encode_image(t)\n",
        "        f = f / f.norm(dim=-1, keepdim=True)\n",
        "        all_feats.append(f.cpu().numpy())\n",
        "\n",
        "image_features = np.vstack(all_feats).astype(np.float32)\n",
        "print(f'Features: {image_features.shape}')\n",
        "\n",
        "# Free GPU memory\n",
        "del clip_model\n",
        "torch.cuda.empty_cache()\n",
        "print('CLIP model unloaded to free GPU memory')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cell 7: Create image-song training pairs\n",
        "norm_cols = [f'{c}_norm' for c in AUDIO_FEATURES]\n",
        "SONGS_PER_IMAGE = 5\n",
        "X, y = [], []\n",
        "for idx, row in tqdm(images_df.iterrows(), total=len(images_df)):\n",
        "    songs = spotify_df[spotify_df['emotion'] == row['emotion']]\n",
        "    if len(songs) == 0: continue\n",
        "    for _, s in songs.sample(min(SONGS_PER_IMAGE, len(songs)), random_state=42+idx).iterrows():\n",
        "        X.append(image_features[idx])\n",
        "        y.append(s[norm_cols].values.astype(np.float32))\n",
        "\n",
        "X, y = np.array(X), np.array(y)\n",
        "print(f'Pairs: {len(X)}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cell 8: Split into train/val/test sets\n",
        "n = len(X)\n",
        "idx = np.random.permutation(n)\n",
        "train_X, train_y = X[idx[:int(0.8*n)]], y[idx[:int(0.8*n)]]\n",
        "val_X, val_y = X[idx[int(0.8*n):int(0.9*n)]], y[idx[int(0.8*n):int(0.9*n)]]\n",
        "test_X, test_y = X[idx[int(0.9*n):]], y[idx[int(0.9*n):]]\n",
        "print(f'Train: {len(train_X)}, Val: {len(val_X)}, Test: {len(test_X)}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cell 9: Define FastMLP model\n",
        "class FastMLP(nn.Module):\n",
        "    \"\"\"Maps CLIP features (512-dim) to Spotify audio features (13-dim)\"\"\"\n",
        "    def __init__(self, input_dim=512, output_dim=13):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(input_dim, 512), nn.BatchNorm1d(512), nn.ReLU(), nn.Dropout(0.2),\n",
        "            nn.Linear(512, 256), nn.BatchNorm1d(256), nn.ReLU(), nn.Dropout(0.2),\n",
        "            nn.Linear(256, 128), nn.BatchNorm1d(128), nn.ReLU(), nn.Dropout(0.2),\n",
        "            nn.Linear(128, output_dim)\n",
        "        )\n",
        "    def forward(self, x): \n",
        "        return self.net(x)\n",
        "\n",
        "model = FastMLP().to(device)\n",
        "print(f'FastMLP Parameters: {sum(p.numel() for p in model.parameters()):,}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cell 10: Training loop\n",
        "EPOCHS = 100\n",
        "BATCH_SIZE = 128\n",
        "PATIENCE = 15  # Early stopping\n",
        "\n",
        "train_loader = DataLoader(TensorDataset(torch.FloatTensor(train_X), torch.FloatTensor(train_y)), batch_size=BATCH_SIZE, shuffle=True)\n",
        "val_loader = DataLoader(TensorDataset(torch.FloatTensor(val_X), torch.FloatTensor(val_y)), batch_size=BATCH_SIZE)\n",
        "\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-5)\n",
        "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, factor=0.5, patience=5)\n",
        "\n",
        "best_loss = float('inf')\n",
        "patience_counter = 0\n",
        "\n",
        "print(f'Training for up to {EPOCHS} epochs (early stopping patience: {PATIENCE})')\n",
        "print('-' * 50)\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    # Training\n",
        "    model.train()\n",
        "    train_loss = 0.0\n",
        "    for bx, by in train_loader:\n",
        "        bx, by = bx.to(device), by.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        loss = criterion(model(bx), by)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        train_loss += loss.item()\n",
        "    train_loss /= len(train_loader)\n",
        "    \n",
        "    # Validation\n",
        "    model.eval()\n",
        "    val_loss = 0.0\n",
        "    with torch.no_grad():\n",
        "        for bx, by in val_loader:\n",
        "            bx, by = bx.to(device), by.to(device)\n",
        "            val_loss += criterion(model(bx), by).item()\n",
        "    val_loss /= len(val_loader)\n",
        "    \n",
        "    scheduler.step(val_loss)\n",
        "    \n",
        "    # Progress\n",
        "    if epoch % 10 == 0 or val_loss < best_loss:\n",
        "        print(f'Epoch {epoch+1:3d}/{EPOCHS} | Train: {train_loss:.4f} | Val: {val_loss:.4f}')\n",
        "    \n",
        "    # Save best\n",
        "    if val_loss < best_loss:\n",
        "        best_loss = val_loss\n",
        "        patience_counter = 0\n",
        "        torch.save(model.state_dict(), '/kaggle/working/best_model.pt')\n",
        "    else:\n",
        "        patience_counter += 1\n",
        "    \n",
        "    # Early stopping\n",
        "    if patience_counter >= PATIENCE:\n",
        "        print(f'\\nEarly stopping at epoch {epoch+1}')\n",
        "        break\n",
        "\n",
        "print('-' * 50)\n",
        "print(f'Training complete! Best val loss: {best_loss:.4f}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cell 11: Save all output files\n",
        "print('Saving output files...')\n",
        "\n",
        "# Load best model\n",
        "model.load_state_dict(torch.load('/kaggle/working/best_model.pt'))\n",
        "\n",
        "# 1. Save model with metadata\n",
        "torch.save({\n",
        "    'model_state_dict': model.state_dict(),\n",
        "    'input_dim': 512,\n",
        "    'output_dim': 13,\n",
        "    'hidden_dims': [512, 256, 128],\n",
        "    'best_val_loss': best_loss\n",
        "}, '/kaggle/working/dylumo_model.pt')\n",
        "print('1. Saved: dylumo_model.pt')\n",
        "\n",
        "# 2. Save scaler\n",
        "with open('/kaggle/working/spotify_scaler.pkl', 'wb') as f:\n",
        "    pickle.dump(scaler, f)\n",
        "print('2. Saved: spotify_scaler.pkl')\n",
        "\n",
        "# 3. Save Spotify features for FAISS\n",
        "np.save('/kaggle/working/spotify_features.npy', spotify_df[norm_cols].values.astype(np.float32))\n",
        "print(f'3. Saved: spotify_features.npy ({len(spotify_df):,} songs)')\n",
        "\n",
        "# 4. Save Spotify metadata\n",
        "cols = ['track_id', 'track_name', 'artist_name', 'popularity', 'emotion']\n",
        "available = [c for c in cols if c in spotify_df.columns]\n",
        "spotify_df[available].to_parquet('/kaggle/working/spotify_metadata.parquet')\n",
        "print('4. Saved: spotify_metadata.parquet')\n",
        "\n",
        "print('\\n' + '=' * 60)\n",
        "print('TRAINING COMPLETE!')\n",
        "print('=' * 60)\n",
        "print('\\nDownload these files from the OUTPUT tab (right sidebar):')\n",
        "print('  - dylumo_model.pt        -> Put in checkpoints/')\n",
        "print('  - spotify_scaler.pkl     -> Put in checkpoints/')\n",
        "print('  - spotify_features.npy   -> Put in data/processed/')\n",
        "print('  - spotify_metadata.parquet -> Put in data/processed/')\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
